// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.30.0
// source: analytics_extended.sql

package database

import (
	"context"
	"time"

	"github.com/google/uuid"
)

const getCollaborationsData = `-- name: GetCollaborationsData :many
SELECT collaborator,
    COUNT(*) as collaboration_count,
    COALESCE(AVG(likes), 0)::BIGINT as avg_likes
FROM (
        SELECT p.author as collaborator,
            COALESCE(prh.likes, 0) as likes
        FROM posts p
            JOIN sources s ON p.source_id = s.id
            LEFT JOIN (
                SELECT DISTINCT ON (post_id) post_id,
                    likes
                FROM posts_reactions_history
                ORDER BY post_id,
                    synced_at DESC
            ) prh ON p.id = prh.post_id
        WHERE s.user_id = $1
            AND p.post_type IN ('repost', 'tag')
            AND p.author IS NOT NULL
            AND p.author != ''
    ) combined_collaborations
GROUP BY collaborator
ORDER BY avg_likes DESC
LIMIT 50
`

type GetCollaborationsDataRow struct {
	Collaborator       string `json:"collaborator"`
	CollaborationCount int64  `json:"collaboration_count"`
	AvgLikes           int64  `json:"avg_likes"`
}

func (q *Queries) GetCollaborationsData(ctx context.Context, userID uuid.UUID) ([]GetCollaborationsDataRow, error) {
	rows, err := q.db.QueryContext(ctx, getCollaborationsData, userID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetCollaborationsDataRow
	for rows.Next() {
		var i GetCollaborationsDataRow
		if err := rows.Scan(&i.Collaborator, &i.CollaborationCount, &i.AvgLikes); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getEngagementRateData = `-- name: GetEngagementRateData :many
SELECT p.id,
    p.network_internal_id,
    p.created_at,
    s.network,
    COALESCE(prh.likes, 0)::BIGINT as likes,
    COALESCE(prh.reposts, 0)::BIGINT as reposts,
    COALESCE(ss.followers_count, 0)::BIGINT as followers_count
FROM posts p
    JOIN sources s ON p.source_id = s.id
    LEFT JOIN (
        SELECT DISTINCT ON (post_id) post_id,
            likes,
            reposts
        FROM posts_reactions_history
        ORDER BY post_id,
            synced_at DESC
    ) prh ON p.id = prh.post_id
    LEFT JOIN LATERAL (
        SELECT followers_count
        FROM sources_stats
        WHERE source_id = s.id
            AND date <= p.created_at
        ORDER BY date DESC
        LIMIT 1
    ) ss ON true
WHERE s.user_id = $1
    AND p.created_at > NOW() - INTERVAL '6 months'
    AND ss.followers_count > 0
`

type GetEngagementRateDataRow struct {
	ID                uuid.UUID `json:"id"`
	NetworkInternalID string    `json:"network_internal_id"`
	CreatedAt         time.Time `json:"created_at"`
	Network           string    `json:"network"`
	Likes             int64     `json:"likes"`
	Reposts           int64     `json:"reposts"`
	FollowersCount    int64     `json:"followers_count"`
}

func (q *Queries) GetEngagementRateData(ctx context.Context, userID uuid.UUID) ([]GetEngagementRateDataRow, error) {
	rows, err := q.db.QueryContext(ctx, getEngagementRateData, userID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetEngagementRateDataRow
	for rows.Next() {
		var i GetEngagementRateDataRow
		if err := rows.Scan(
			&i.ID,
			&i.NetworkInternalID,
			&i.CreatedAt,
			&i.Network,
			&i.Likes,
			&i.Reposts,
			&i.FollowersCount,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getEngagementVelocityData = `-- name: GetEngagementVelocityData :many
SELECT prh.post_id,
    prh.synced_at as history_synced_at,
    COALESCE(prh.likes, 0)::BIGINT as likes,
    COALESCE(prh.reposts, 0)::BIGINT as reposts,
    p.created_at as post_created_at,
    COALESCE(p.content, '')::TEXT as content,
    p.author,
    p.network_internal_id,
    s.network
FROM posts_reactions_history prh
    JOIN posts p ON prh.post_id = p.id
    JOIN sources s ON p.source_id = s.id
    JOIN (
        SELECT post_id,
            MIN(synced_at) as first_synced
        FROM posts_reactions_history
        GROUP BY post_id
    ) first_sync ON p.id = first_sync.post_id
WHERE s.user_id = $1
    AND p.created_at > NOW() - INTERVAL '30 days'
    AND p.post_type NOT IN ('tag', 'repost', 'quote')
    AND DATE(p.created_at) = DATE(first_sync.first_synced)
ORDER BY prh.post_id,
    prh.synced_at ASC
`

type GetEngagementVelocityDataRow struct {
	PostID            uuid.UUID `json:"post_id"`
	HistorySyncedAt   time.Time `json:"history_synced_at"`
	Likes             int64     `json:"likes"`
	Reposts           int64     `json:"reposts"`
	PostCreatedAt     time.Time `json:"post_created_at"`
	Content           string    `json:"content"`
	Author            string    `json:"author"`
	NetworkInternalID string    `json:"network_internal_id"`
	Network           string    `json:"network"`
}

func (q *Queries) GetEngagementVelocityData(ctx context.Context, userID uuid.UUID) ([]GetEngagementVelocityDataRow, error) {
	rows, err := q.db.QueryContext(ctx, getEngagementVelocityData, userID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetEngagementVelocityDataRow
	for rows.Next() {
		var i GetEngagementVelocityDataRow
		if err := rows.Scan(
			&i.PostID,
			&i.HistorySyncedAt,
			&i.Likes,
			&i.Reposts,
			&i.PostCreatedAt,
			&i.Content,
			&i.Author,
			&i.NetworkInternalID,
			&i.Network,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getFollowRatioData = `-- name: GetFollowRatioData :many
SELECT s.network,
    s.user_name,
    COALESCE(ss.followers_count, 0)::BIGINT as followers_count,
    COALESCE(ss.following_count, 0)::BIGINT as following_count
FROM sources s
    JOIN LATERAL (
        SELECT followers_count,
            following_count
        FROM sources_stats
        WHERE source_id = s.id
        ORDER BY date DESC
        LIMIT 1
    ) ss ON true
WHERE s.user_id = $1
    AND ss.followers_count > 0
    AND ss.following_count > 0
`

type GetFollowRatioDataRow struct {
	Network        string `json:"network"`
	UserName       string `json:"user_name"`
	FollowersCount int64  `json:"followers_count"`
	FollowingCount int64  `json:"following_count"`
}

func (q *Queries) GetFollowRatioData(ctx context.Context, userID uuid.UUID) ([]GetFollowRatioDataRow, error) {
	rows, err := q.db.QueryContext(ctx, getFollowRatioData, userID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetFollowRatioDataRow
	for rows.Next() {
		var i GetFollowRatioDataRow
		if err := rows.Scan(
			&i.Network,
			&i.UserName,
			&i.FollowersCount,
			&i.FollowingCount,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getGlobalPostTypeAnalytics = `-- name: GetGlobalPostTypeAnalytics :many
SELECT post_type,
    count(*) as post_count,
    COALESCE(AVG(prh.likes), 0)::BIGINT as avg_likes
FROM posts p
    JOIN sources s ON p.source_id = s.id
    LEFT JOIN (
        SELECT DISTINCT ON (post_id) post_id,
            likes
        FROM posts_reactions_history
        ORDER BY post_id,
            synced_at DESC
    ) prh ON p.id = prh.post_id
WHERE s.user_id = $1
GROUP BY post_type
ORDER BY avg_likes DESC
`

type GetGlobalPostTypeAnalyticsRow struct {
	PostType  string `json:"post_type"`
	PostCount int64  `json:"post_count"`
	AvgLikes  int64  `json:"avg_likes"`
}

func (q *Queries) GetGlobalPostTypeAnalytics(ctx context.Context, userID uuid.UUID) ([]GetGlobalPostTypeAnalyticsRow, error) {
	rows, err := q.db.QueryContext(ctx, getGlobalPostTypeAnalytics, userID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetGlobalPostTypeAnalyticsRow
	for rows.Next() {
		var i GetGlobalPostTypeAnalyticsRow
		if err := rows.Scan(&i.PostType, &i.PostCount, &i.AvgLikes); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getHashtagAnalytics = `-- name: GetHashtagAnalytics :many
SELECT substring(
        word
        from 2
    ) as tag,
    count(*) as usage_count,
    COALESCE(AVG(prh.likes), 0)::BIGINT as avg_likes,
    COALESCE(AVG(prh.views), 0)::BIGINT as avg_views
FROM (
        SELECT regexp_split_to_table(lower(content), '\s+') as word,
            posts.id as post_id
        FROM posts
            JOIN sources s ON posts.source_id = s.id
        WHERE s.user_id = $1
            AND content IS NOT NULL
    ) t
    LEFT JOIN (
        SELECT DISTINCT ON (post_id) post_id,
            likes,
            views
        FROM posts_reactions_history
        ORDER BY post_id,
            synced_at DESC
    ) prh ON t.post_id = prh.post_id
WHERE word LIKE '#%'
    AND length(word) > 1
GROUP BY tag
ORDER BY usage_count DESC
LIMIT 20
`

type GetHashtagAnalyticsRow struct {
	Tag        interface{} `json:"tag"`
	UsageCount int64       `json:"usage_count"`
	AvgLikes   int64       `json:"avg_likes"`
	AvgViews   int64       `json:"avg_views"`
}

func (q *Queries) GetHashtagAnalytics(ctx context.Context, userID uuid.UUID) ([]GetHashtagAnalyticsRow, error) {
	rows, err := q.db.QueryContext(ctx, getHashtagAnalytics, userID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetHashtagAnalyticsRow
	for rows.Next() {
		var i GetHashtagAnalyticsRow
		if err := rows.Scan(
			&i.Tag,
			&i.UsageCount,
			&i.AvgLikes,
			&i.AvgViews,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getMentionsAnalytics = `-- name: GetMentionsAnalytics :many
SELECT regexp_replace(
        substring(
            word
            from 2
        ),
        '[^a-z0-9_.]',
        '',
        'g'
    ) as mention,
    count(*) as usage_count,
    COALESCE(AVG(prh.likes), 0)::BIGINT as avg_likes
FROM (
        SELECT regexp_split_to_table(lower(content), '\s+') as word,
            posts.id as post_id
        FROM posts
            JOIN sources s ON posts.source_id = s.id
        WHERE s.user_id = $1
            AND content IS NOT NULL
    ) t
    LEFT JOIN (
        SELECT DISTINCT ON (post_id) post_id,
            likes
        FROM posts_reactions_history
        ORDER BY post_id,
            synced_at DESC
    ) prh ON t.post_id = prh.post_id
WHERE word LIKE '@%'
GROUP BY mention
HAVING length(
        regexp_replace(
            substring(
                word
                from 2
            ),
            '[^a-z0-9_.]',
            '',
            'g'
        )
    ) > 1
ORDER BY avg_likes DESC
LIMIT 20
`

type GetMentionsAnalyticsRow struct {
	Mention    string `json:"mention"`
	UsageCount int64  `json:"usage_count"`
	AvgLikes   int64  `json:"avg_likes"`
}

func (q *Queries) GetMentionsAnalytics(ctx context.Context, userID uuid.UUID) ([]GetMentionsAnalyticsRow, error) {
	rows, err := q.db.QueryContext(ctx, getMentionsAnalytics, userID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetMentionsAnalyticsRow
	for rows.Next() {
		var i GetMentionsAnalyticsRow
		if err := rows.Scan(&i.Mention, &i.UsageCount, &i.AvgLikes); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getNetworkEfficiency = `-- name: GetNetworkEfficiency :many
SELECT s.network,
    count(*) as post_count,
    COALESCE(AVG(prh.likes), 0)::BIGINT as avg_likes,
    COALESCE(AVG(prh.reposts), 0)::BIGINT as avg_reposts
FROM posts p
    JOIN sources s ON p.source_id = s.id
    LEFT JOIN (
        SELECT DISTINCT ON (post_id) post_id,
            likes,
            reposts
        FROM posts_reactions_history
        ORDER BY post_id,
            synced_at DESC
    ) prh ON p.id = prh.post_id
WHERE s.user_id = $1
GROUP BY s.network
ORDER BY avg_likes DESC
`

type GetNetworkEfficiencyRow struct {
	Network    string `json:"network"`
	PostCount  int64  `json:"post_count"`
	AvgLikes   int64  `json:"avg_likes"`
	AvgReposts int64  `json:"avg_reposts"`
}

func (q *Queries) GetNetworkEfficiency(ctx context.Context, userID uuid.UUID) ([]GetNetworkEfficiencyRow, error) {
	rows, err := q.db.QueryContext(ctx, getNetworkEfficiency, userID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetNetworkEfficiencyRow
	for rows.Next() {
		var i GetNetworkEfficiencyRow
		if err := rows.Scan(
			&i.Network,
			&i.PostCount,
			&i.AvgLikes,
			&i.AvgReposts,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPerformanceDeviationData = `-- name: GetPerformanceDeviationData :many
WITH SourceAverages AS (
    SELECT p.source_id,
        AVG(
            COALESCE(prh.likes, 0) + COALESCE(prh.reposts, 0)
        ) as avg_engagement
    FROM posts p
        LEFT JOIN (
            SELECT DISTINCT ON (post_id) post_id,
                likes,
                reposts
            FROM posts_reactions_history
            ORDER BY post_id,
                synced_at DESC
        ) prh ON p.id = prh.post_id
    GROUP BY p.source_id
)
SELECT p.id,
    p.network_internal_id,
    COALESCE(p.content, '')::TEXT as content,
    p.created_at,
    p.author,
    s.network,
    COALESCE(prh.likes, 0)::BIGINT as likes,
    COALESCE(prh.reposts, 0)::BIGINT as reposts,
    (
        sa.avg_engagement * LEAST(
            1.0,
            EXTRACT(
                EPOCH
                FROM (NOW() - p.created_at)
            ) / 86400.0
        )
    )::FLOAT as expected_engagement
FROM posts p
    JOIN sources s ON p.source_id = s.id
    JOIN SourceAverages sa ON p.source_id = sa.source_id
    LEFT JOIN (
        SELECT DISTINCT ON (post_id) post_id,
            likes,
            reposts
        FROM posts_reactions_history
        ORDER BY post_id,
            synced_at DESC
    ) prh ON p.id = prh.post_id
WHERE s.user_id = $1
    AND p.post_type NOT IN ('tag', 'repost', 'quote')
ORDER BY ABS(
        (
            COALESCE(prh.likes, 0) + COALESCE(prh.reposts, 0)
        ) - (
            sa.avg_engagement * LEAST(
                1.0,
                EXTRACT(
                    EPOCH
                    FROM (NOW() - p.created_at)
                ) / 86400.0
            )
        )
    ) DESC
LIMIT 100
`

type GetPerformanceDeviationDataRow struct {
	ID                 uuid.UUID `json:"id"`
	NetworkInternalID  string    `json:"network_internal_id"`
	Content            string    `json:"content"`
	CreatedAt          time.Time `json:"created_at"`
	Author             string    `json:"author"`
	Network            string    `json:"network"`
	Likes              int64     `json:"likes"`
	Reposts            int64     `json:"reposts"`
	ExpectedEngagement float64   `json:"expected_engagement"`
}

func (q *Queries) GetPerformanceDeviationData(ctx context.Context, userID uuid.UUID) ([]GetPerformanceDeviationDataRow, error) {
	rows, err := q.db.QueryContext(ctx, getPerformanceDeviationData, userID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetPerformanceDeviationDataRow
	for rows.Next() {
		var i GetPerformanceDeviationDataRow
		if err := rows.Scan(
			&i.ID,
			&i.NetworkInternalID,
			&i.Content,
			&i.CreatedAt,
			&i.Author,
			&i.Network,
			&i.Likes,
			&i.Reposts,
			&i.ExpectedEngagement,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPostingConsistency = `-- name: GetPostingConsistency :many
SELECT TO_CHAR(p.created_at, 'YYYY-MM-DD') as date_str,
    count(*) as post_count
FROM posts p
    JOIN sources s ON p.source_id = s.id
WHERE s.user_id = $1
    AND p.created_at > NOW() - INTERVAL '1 year'
GROUP BY date_str
ORDER BY date_str
`

type GetPostingConsistencyRow struct {
	DateStr   string `json:"date_str"`
	PostCount int64  `json:"post_count"`
}

func (q *Queries) GetPostingConsistency(ctx context.Context, userID uuid.UUID) ([]GetPostingConsistencyRow, error) {
	rows, err := q.db.QueryContext(ctx, getPostingConsistency, userID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetPostingConsistencyRow
	for rows.Next() {
		var i GetPostingConsistencyRow
		if err := rows.Scan(&i.DateStr, &i.PostCount); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getSiteStatsOverTime = `-- name: GetSiteStatsOverTime :many
SELECT date_str, total_visitors, avg_session_duration
FROM (
        SELECT TO_CHAR(DATE_TRUNC('week', date), 'IYYY-"W"IW') as date_str,
            COALESCE(SUM(visitors), 0)::BIGINT as total_visitors,
            COALESCE(AVG(avg_session_duration), 0)::FLOAT as avg_session_duration
        FROM analytics_site_stats ass
            JOIN sources s ON ass.source_id = s.id
        WHERE s.user_id = $1
        GROUP BY DATE_TRUNC('week', date)
        ORDER BY DATE_TRUNC('week', date) DESC
        LIMIT 52
    ) recent_weeks
ORDER BY date_str ASC
`

type GetSiteStatsOverTimeRow struct {
	DateStr            string  `json:"date_str"`
	TotalVisitors      int64   `json:"total_visitors"`
	AvgSessionDuration float64 `json:"avg_session_duration"`
}

func (q *Queries) GetSiteStatsOverTime(ctx context.Context, userID uuid.UUID) ([]GetSiteStatsOverTimeRow, error) {
	rows, err := q.db.QueryContext(ctx, getSiteStatsOverTime, userID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetSiteStatsOverTimeRow
	for rows.Next() {
		var i GetSiteStatsOverTimeRow
		if err := rows.Scan(&i.DateStr, &i.TotalVisitors, &i.AvgSessionDuration); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getTimePerformance = `-- name: GetTimePerformance :many
SELECT EXTRACT(
        DOW
        FROM p.created_at
    )::INT as day_of_week,
    EXTRACT(
        HOUR
        FROM p.created_at
    )::INT as hour_of_day,
    COALESCE(AVG(prh.likes), 0)::BIGINT as avg_likes
FROM posts p
    JOIN sources s ON p.source_id = s.id
    LEFT JOIN (
        SELECT DISTINCT ON (post_id) post_id,
            likes
        FROM posts_reactions_history
        ORDER BY post_id,
            synced_at DESC
    ) prh ON p.id = prh.post_id
WHERE s.user_id = $1
GROUP BY day_of_week,
    hour_of_day
ORDER BY day_of_week,
    hour_of_day
`

type GetTimePerformanceRow struct {
	DayOfWeek int32 `json:"day_of_week"`
	HourOfDay int32 `json:"hour_of_day"`
	AvgLikes  int64 `json:"avg_likes"`
}

func (q *Queries) GetTimePerformance(ctx context.Context, userID uuid.UUID) ([]GetTimePerformanceRow, error) {
	rows, err := q.db.QueryContext(ctx, getTimePerformance, userID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetTimePerformanceRow
	for rows.Next() {
		var i GetTimePerformanceRow
		if err := rows.Scan(&i.DayOfWeek, &i.HourOfDay, &i.AvgLikes); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getTopPagesByViews = `-- name: GetTopPagesByViews :many
SELECT url_path,
    COALESCE(SUM(views), 0)::BIGINT as total_views
FROM analytics_page_stats aps
    JOIN sources s ON aps.source_id = s.id
WHERE s.user_id = $1
GROUP BY url_path
ORDER BY total_views DESC
LIMIT 50
`

type GetTopPagesByViewsRow struct {
	UrlPath    string `json:"url_path"`
	TotalViews int64  `json:"total_views"`
}

func (q *Queries) GetTopPagesByViews(ctx context.Context, userID uuid.UUID) ([]GetTopPagesByViewsRow, error) {
	rows, err := q.db.QueryContext(ctx, getTopPagesByViews, userID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetTopPagesByViewsRow
	for rows.Next() {
		var i GetTopPagesByViewsRow
		if err := rows.Scan(&i.UrlPath, &i.TotalViews); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getWordCloudData = `-- name: GetWordCloudData :many
SELECT cleaned_word as word,
    count(*) as count
FROM (
        SELECT regexp_replace(
                lower(regexp_split_to_table(content, '\s+')),
                '[^a-z0-9]',
                '',
                'g'
            ) as cleaned_word,
            regexp_split_to_table(content, '\s+') as raw_word
        FROM posts
            JOIN sources s ON posts.source_id = s.id
        WHERE s.user_id = $1
            AND content IS NOT NULL
    ) t
WHERE length(cleaned_word) > 3
    AND raw_word NOT LIKE '#%'
    AND raw_word NOT LIKE '@%'
    AND raw_word NOT LIKE 'http%'
    AND raw_word NOT ILIKE '%http%'
    AND raw_word NOT ILIKE '%www.%'
    AND raw_word NOT ILIKE '%.com%'
    AND cleaned_word NOT ILIKE '%iotpho%'
    AND cleaned_word NOT IN (
        'that',
        'have',
        'with',
        'this',
        'from',
        'they',
        'will',
        'would',
        'there',
        'their',
        'about',
        'which',
        'when',
        'make',
        'like',
        'time',
        'just',
        'know',
        'take',
        'what',
        'people',
        'into',
        'year',
        'your',
        'good',
        'some',
        'could',
        'them',
        'other',
        'cant',
        'than',
        'then',
        'look',
        'only',
        'come',
        'over',
        'think',
        'also',
        'back',
        'after',
        'work',
        'first',
        'well',
        'even',
        'want',
        'because',
        'these',
        'give',
        'most',
        'were',
        'been',
        'here',
        'many',
        'dont',
        'does',
        'more',
        'less'
    )
GROUP BY cleaned_word
ORDER BY count DESC
LIMIT 50
`

type GetWordCloudDataRow struct {
	Word  string `json:"word"`
	Count int64  `json:"count"`
}

func (q *Queries) GetWordCloudData(ctx context.Context, userID uuid.UUID) ([]GetWordCloudDataRow, error) {
	rows, err := q.db.QueryContext(ctx, getWordCloudData, userID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetWordCloudDataRow
	for rows.Next() {
		var i GetWordCloudDataRow
		if err := rows.Scan(&i.Word, &i.Count); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}
